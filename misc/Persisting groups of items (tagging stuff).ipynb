{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "881b2c1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T15:22:19.235400Z",
     "start_time": "2023-04-20T15:22:19.188832Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229668f7",
   "metadata": {},
   "source": [
    "This notebook is meant to demo a few dev techniques when tackling a new problem. \n",
    "\n",
    "It involves: TDD, typing, scaffolding, protocols, facades, repository pattern,... "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f4d676",
   "metadata": {},
   "source": [
    "## The problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ac12bf",
   "metadata": {},
   "source": [
    "The original problem: **As a user, I can tag (recording) sessions, view my tags, and retrieve the sessions for a given tag.**\n",
    "\n",
    "Questions:\n",
    "\n",
    "- Where do I store the tag/sessions info?\n",
    "- How (what data structure, what am I actually storing)?\n",
    "\n",
    "Answers:\n",
    "\n",
    "Shouldn't start with those questions. Those questions have to do with specifics. Of course, we'll need to make choices about those questions eventually, but we'll produce a brittle code-base if we don't first think of abstractions.\n",
    "\n",
    "Let's first think of a more general expression of what we're actually trying to do, and find a less specific vocabulary to describe it. We can (maybe even should) reintroduce the domain-specific vocabulary, as a layer on top of the more general mechanism, but we want to give ourselves a chance of knowing what the more abstract problem pattern is.\n",
    "\n",
    "The transformed, more general, so reusable, problem: **Same as above but replace \"tag\" with \"group\" and \"sessions\" with \"items\".**\n",
    "\n",
    "Then:\n",
    "\n",
    "* First look at what makes sense in the domain/interface -- Express this with types and tests\n",
    "\n",
    "* Then implement the interface, with a backend that corresponds to the current constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8925e753",
   "metadata": {},
   "source": [
    "## A little digression on scaffolding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c50b2ee3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T15:28:35.161809Z",
     "start_time": "2023-04-20T15:28:35.151674Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import MutableMapping, Iterable, Any, NewType, Callable\n",
    "\n",
    "Group = NewType('Group', str)\n",
    "Item = NewType('Item', Any)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b31c82f",
   "metadata": {},
   "source": [
    "What functionality do we want around groups and their items?\n",
    "\n",
    "Let's express this through type annotations of some functions (which we'll encapsulate in a `Groups` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "448dd939",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T15:28:36.495757Z",
     "start_time": "2023-04-20T15:28:36.489408Z"
    }
   },
   "outputs": [],
   "source": [
    "class GroupsDacc:\n",
    "    add_items_to_group: Callable[[Iterable[Item], Group], Any]\n",
    "    list_groups: Callable[[], Iterable[Group]]\n",
    "    items_for_group: Callable[[Group],Iterable[Item]]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda46582",
   "metadata": {},
   "source": [
    "Note that this should now be sufficient to generate a scaffold of what we need. \n",
    "\n",
    "We'll do it in two ways: By (dynamically) creating a `typing.protocol` describing a concrete `Groups` object we could implement in the future, and by generating (the code string for) a concrete (but empty) such `Groups` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db79dbf0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T15:28:37.755133Z",
     "start_time": "2023-04-20T15:28:37.475516Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Sig (self, iterable: Iterable[__main__.Item], group: __main__.Group) -> Any>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import i2\n",
    "\n",
    "from meshed.scrap.annotations_to_meshes import (\n",
    "    func_types_to_scaffold, \n",
    "    func_types_to_protocol\n",
    ")\n",
    "\n",
    "# Groups.__annotations__ is a {name: func_annotation, ...} dict\n",
    "# We can make a protocol from that\n",
    "GroupsProtocol = func_types_to_protocol(GroupsDacc.__annotations__)\n",
    "\n",
    "# See that GroupsProtocol has methods for each item of the \n",
    "# Groups.__annotations__ dict. Each method bares a signature compatible with \n",
    "# the annotations.\n",
    "i2.Sig(GroupsProtocol.add_items_to_group)\n",
    "# <Sig (self, iterable: Iterable[__main__.Item], group: __main__.Group) -> Any>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fca3d3c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T15:28:39.488081Z",
     "start_time": "2023-04-20T15:28:39.482538Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "class GeneratedClass:\n",
      "    def add_items_to_group(self, iterable: Iterable, group: Group) -> Any:\n",
      "    \tpass\n",
      "\n",
      "    def list_groups(self) -> Iterable:\n",
      "    \tpass\n",
      "\n",
      "    def items_for_group(self, group: Group) -> Iterable:\n",
      "    \tpass\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We can also \n",
    "print(func_types_to_scaffold(GroupsDacc.__annotations__))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa5c57c",
   "metadata": {},
   "source": [
    "## TDD: Tests that describe the behavior we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c94c4732",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T15:29:27.992317Z",
     "start_time": "2023-04-20T15:29:27.981533Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import MutableMapping, Iterable, Any, NewType, Callable, Protocol\n",
    "\n",
    "Group = NewType('Group', str)\n",
    "Item = NewType('Item', Any)\n",
    "\n",
    "\n",
    "class GroupsProtocol(Protocol):\n",
    "    def add_items_to_group(self, iterable: Iterable, group: Group) -> Any:\n",
    "        \"\"\"Add one or several items to a group\"\"\"\n",
    "\n",
    "    def list_groups(self) -> Iterable:\n",
    "        \"\"\"List group names\"\"\"\n",
    "\n",
    "    def items_for_group(self, group: Group) -> Iterable:\n",
    "        \"\"\"List the items in a group\"\"\"\n",
    "    \n",
    "    \n",
    "def test_groups(groups: GroupsProtocol):\n",
    "    # the following assertion isn't part of the behavior we want -- just a condition we'll \n",
    "    # need to be able to conduct our test: Namely, that our collection of groups/items is empty.\n",
    "    assert list(groups.list_groups()) == []  # make sure test is well setup\n",
    "    \n",
    "    groups.add_items_to_group('group_a', 'item_1', 'item_2')\n",
    "    assert sorted(groups.list_groups()) == ['group_a']\n",
    "    \n",
    "    groups.add_items_to_group('group_b', 'item_3')\n",
    "    assert sorted(groups.list_groups()) == ['group_a', 'group_b']\n",
    "    assert sorted(groups.items_for_group('group_a')) == ['item_1', 'item_2']\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448607c4",
   "metadata": {},
   "source": [
    "Now we'll implement two concrete `GroupsDacc`, using a store, a `MutableMapping`, as a back-end so as to keep the persistance concern still separate. \n",
    "\n",
    "The idea is: As long as we provide our concrete persister with the right `MutableMapping` facade (with a minimum of specifics/semantics such as what the keys and values are meant to be), we should have a working object.\n",
    "\n",
    "The two `GroupsDacc` options will differ on the particulars of the store. \n",
    "- In the first, we'll assume the store has items as keys and groups as values. \n",
    "- In the second we'll assume the groups are the keys, and values are sets of items of that group."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce4020d",
   "metadata": {},
   "source": [
    "## Concrete GroupsDacc (option 1): ItemGroupDacc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c92de33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T15:31:03.078989Z",
     "start_time": "2023-04-20T15:31:03.069787Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import MutableMapping, Iterable, Any, NewType\n",
    "from dataclasses import dataclass\n",
    "\n",
    "Group = NewType('Group', str)\n",
    "Item = NewType('Item', Any)\n",
    "ItemGroupPairs = NewType('ItemGroupPairs', MutableMapping[Item, Group])\n",
    "\n",
    "@dataclass\n",
    "class ItemGroupDacc:\n",
    "    store: ItemGroupPairs\n",
    "        \n",
    "    def add_items_to_group(self, group: Group, *items: Iterable[Item]) -> Any:\n",
    "        for item in items:\n",
    "            self.store[item] = group\n",
    "\n",
    "    def list_groups(self) -> Iterable[Group]:\n",
    "        return set(self.store.values())\n",
    "\n",
    "    def items_for_group(self, group: Group) -> Iterable[Item]:\n",
    "        # TODO: Exxpress this filtering in such a way that will allow us to take advantage of DB specifics\n",
    "        #  (e.g., passing on the filtering to the DB instead of filtering in python itself)\n",
    "        return (item for item, group_ in self.store.items() if group_ == group)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7998b08d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T15:31:03.737748Z",
     "start_time": "2023-04-20T15:31:03.730886Z"
    }
   },
   "outputs": [],
   "source": [
    "store = dict()\n",
    "test_groups(ItemGroupDacc(store))  # a dict works!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c499ffcc",
   "metadata": {},
   "source": [
    "## Concrete GroupsDacc (option 2): GroupSetsDacc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee2b5276",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T15:31:04.563675Z",
     "start_time": "2023-04-20T15:31:04.554402Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import MutableMapping, Iterable, Any, NewType, Set\n",
    "from dataclasses import dataclass\n",
    "\n",
    "Group = NewType('Group', str)\n",
    "Item = NewType('Item', Any)\n",
    "GroupSets = NewType('GroupSets', MutableMapping[Group, Set[Item]])\n",
    "\n",
    "@dataclass\n",
    "class GroupSetsDacc:\n",
    "    store: GroupSets\n",
    "        \n",
    "    def add_items_to_group(self, group: Group, *items: Iterable[Item]) -> Any:\n",
    "        self.store[group] |= set(items)\n",
    "\n",
    "    def list_groups(self) -> Iterable[Group]:\n",
    "        return set(self.store)\n",
    "            \n",
    "    def items_for_group(self, group: Group) -> Iterable[Item]:\n",
    "        return self.store[group]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "120e4432",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T15:31:05.089457Z",
     "start_time": "2023-04-20T15:31:05.082179Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "store = defaultdict(set)\n",
    "test_groups(GroupSetsDacc(store))  # a defaultdict(set) works as a store!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d774183f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86e23a7b",
   "metadata": {},
   "source": [
    "## Actual persisting stores using mongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dccfa801",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T15:31:06.184059Z",
     "start_time": "2023-04-20T15:31:06.177757Z"
    }
   },
   "outputs": [],
   "source": [
    "# from mongodol.base import MongoClient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e30fc6",
   "metadata": {},
   "source": [
    "### ItemGroupPairs (for ItemGroupDacc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f92e87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T16:13:01.269936Z",
     "start_time": "2023-04-19T16:13:01.245529Z"
    }
   },
   "source": [
    "Options for implementing:\n",
    "\n",
    "```\n",
    "s[item] = group\n",
    "```\n",
    "\n",
    "Option 1: But here we'd need to produce the ID on write\n",
    "\n",
    "```\n",
    "--> {'_id': ID, 'group': group', 'item': item}\n",
    "```\n",
    "\n",
    "Option 2: But we need to allow re-writes on `_id`\n",
    "\n",
    "```\n",
    "--> {'_id': item, 'group': group}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "50eaa0ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T15:32:38.171203Z",
     "start_time": "2023-04-20T15:32:38.137796Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from dol import wrap_kvs, Pipe\n",
    "from mongodol.stores import MongoStore\n",
    "\n",
    "\n",
    "# To be able to overwrite an existing (item, group) pair (by default MongoStore doesn't allow it)\n",
    "def delete_if_exists(self, k, v):\n",
    "    if k in self:\n",
    "        del self[k]\n",
    "    return v\n",
    "\n",
    "\n",
    "trans = Pipe(\n",
    "    wrap_kvs(\n",
    "        key_of_id=itemgetter('_id'), \n",
    "        id_of_key=lambda x: {'_id': x}, \n",
    "        obj_of_data=itemgetter('group'),\n",
    "        data_of_obj=lambda x: {'group': x}, \n",
    "        preset=delete_if_exists,\n",
    "    )\n",
    ")\n",
    "\n",
    "@trans\n",
    "class GroupStore(MongoStore):\n",
    "    \"\"\"To group items\"\"\"\n",
    "    def __init__(self,\n",
    "        db_name='scrap',\n",
    "        collection_name='group_items',\n",
    "        mongo_client_kwargs=None,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            db_name=db_name,\n",
    "            collection_name=collection_name,\n",
    "            key_fields=['_id'],\n",
    "            data_fields=['group'],\n",
    "            mongo_client_kwargs=mongo_client_kwargs\n",
    "        )\n",
    "    \n",
    "m = GroupStore()\n",
    "list(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e6e6eae6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T15:32:38.713083Z",
     "start_time": "2023-04-20T15:32:38.565314Z"
    }
   },
   "outputs": [],
   "source": [
    "store = GroupStore()\n",
    "\n",
    "# empty the store\n",
    "for k in store: \n",
    "    del store[k]\n",
    "\n",
    "test_groups(ItemGroupDacc(store))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae5ce6e",
   "metadata": {},
   "source": [
    "### GroupSets (for GroupSetsDacc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52182f0d",
   "metadata": {},
   "source": [
    "Options for implementing:\n",
    "\n",
    "```\n",
    "s[group] |= items\n",
    "```\n",
    "\n",
    "Option 1: But here we'd need to produce the ID on write\n",
    "\n",
    "```\n",
    "--> {'_id': group, 'items': items}\n",
    "```\n",
    "\n",
    "Option 2: But we need to allow re-writes on `_id`\n",
    "\n",
    "```\n",
    "--> {'_id': ID, 'group': group, 'item': item}  # (group, items) -> (group, item_1), (group, item_2), ...\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "97c5af0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T15:46:06.549279Z",
     "start_time": "2023-04-20T15:46:06.533831Z"
    }
   },
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from dol import wrap_kvs, Pipe\n",
    "from mongodol.stores import MongoStore\n",
    "\n",
    "\n",
    "# To be able to overwrite an existing (item, group) pair (by default MongoStore doesn't allow it)\n",
    "def delete_if_exists(self, k, v):\n",
    "    if k in self:\n",
    "        del self[k]\n",
    "    return v\n",
    "\n",
    "\n",
    "trans = Pipe(\n",
    "    wrap_kvs(\n",
    "        key_of_id=itemgetter('_id'), \n",
    "        id_of_key=lambda x: {'_id': x}, \n",
    "        obj_of_data=Pipe(itemgetter('items'), set),\n",
    "        data_of_obj=lambda x: {'items': list(x) if not isinstance(x, str) else [x]}, \n",
    "#         preset=delete_if_exists,\n",
    "    )\n",
    ")\n",
    "\n",
    "@trans\n",
    "class ItemsStore(MongoStore):\n",
    "    \"\"\"To group items\"\"\"\n",
    "    def __init__(self,\n",
    "        db_name='scrap',\n",
    "        collection_name='items_group',\n",
    "        mongo_client_kwargs=None,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            db_name=db_name,\n",
    "            collection_name=collection_name,\n",
    "            key_fields=['_id'],\n",
    "            data_fields=['items'],\n",
    "            mongo_client_kwargs=mongo_client_kwargs\n",
    "        )\n",
    "        \n",
    "    def __missing__(self, k):\n",
    "        return {'items': []}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8e3cd3f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T15:46:35.209905Z",
     "start_time": "2023-04-20T15:46:35.177491Z"
    }
   },
   "outputs": [],
   "source": [
    "store = ItemsStore()\n",
    "\n",
    "# empty the store\n",
    "for k in store: \n",
    "    del store[k]\n",
    "\n",
    "test_groups(GroupSetsDacc(store))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74670b4c",
   "metadata": {},
   "source": [
    "## Implementation that uses \"metadata\" collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb4e7eb",
   "metadata": {},
   "source": [
    "Say you already have a mongo collection that contains meta-data on your items. \n",
    "That is, a collection that contains docs, one per item, that is intended to record information about this item. \n",
    "The groups the item belongs to can be just one additional one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec52e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_docs = [\n",
    "    {\n",
    "        \"_id\": \"123\",\n",
    "        \"ref\": \"absolute/reference/to/content\",\n",
    "        \"some\": \"other metadata\",  # just to show there can be other stuff\n",
    "        \"groups\": {\n",
    "            # instead of a list, we'll use an object (dict), whose fields are the group names\n",
    "            # This is because mongoDB allows us to index fields, therefore automatically \n",
    "            # get the bidirectional mapping from groups to refs the group \"contains\"\n",
    "            \"group1\": True,\n",
    "            \"group2\": True,\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"_id\": \"456\",\n",
    "        \"ref\": \"absolute/reference/to/some/other/content\",\n",
    "        \"groups\": {\n",
    "            \"group1\": True,\n",
    "            \"group3\": True,\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"_id\": \"789\",\n",
    "        \"ref\": \"this/ref/is/necessary\",\n",
    "        \"optional\": \"metadata\",\n",
    "        # and not groups here (but whenever someone/something adds a group, it will be added here)\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214b7a50",
   "metadata": {},
   "source": [
    "\n",
    "# Extension (and refactoring) Proposal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5daf726d",
   "metadata": {},
   "source": [
    "I'd like to extend the groups protocol further. \n",
    "Namely, enabling the inverse of `items_for_group`, which I'll call `groups_for_item`, \n",
    "and merge it with `list_groups` itself, enabling `list_groups` with item filtering capabilities.\n",
    "\n",
    "I'd like to also consider replacing \n",
    "\"groups\" with \"tags\" (because the \"objects can have multiple tags\" \n",
    "seems more obvious than \"multiple groups\")\n",
    "and \"items\" with \"objs\" (because items clashes with the Mapping interface - and `object` is a reserved word (`obj` is not)).\n",
    "Suggestions welcomed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f473ba51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import MutableMapping, Iterable, Any, NewType, Callable, Protocol, Optional\n",
    "\n",
    "Tag = NewType('Tag', str)\n",
    "Obj = NewType('Object', Any)  # or just object?\n",
    "\n",
    "\n",
    "class TaggerProtocol(Protocol):\n",
    "    def tag_objs(self, tag: Tag, *objs: Iterable[Obj]) -> Any:\n",
    "        \"\"\"tag one or several objs \"\"\"\n",
    "\n",
    "    def tags(self, obj: Optional[Obj] = None) -> Iterable[Tag]:\n",
    "        \"\"\"List tags of obj, or all tags if obj is None\"\"\"\n",
    "\n",
    "    def objs(self, tag: Optional[Tag] = None) -> Iterable[Obj]:\n",
    "        \"\"\"List objs with tag, or all objs if tag is None\"\"\"\n",
    "    \n",
    "    \n",
    "def test_tagger(tagger: TaggerProtocol):\n",
    "    # the following assertion isn't part of the behavior we want -- just a condition we'll \n",
    "    # need to be able to conduct our test: Namely, that our collection of groups/items is empty.\n",
    "\n",
    "    assert list(tagger.tags()) == []  # make sure test is well setup (tagger is empty)\n",
    "\n",
    "    tagger.tag_objs('tag_a', 'obj_1', 'obj_2')\n",
    "    assert sorted(tagger.tags()) == ['tag_a']  # unfiltered tags() method\n",
    "\n",
    "    tagger.tag_objs('tag_b', 'obj_3')\n",
    "    assert sorted(tagger.tags()) == ['tag_a', 'tag_b']  \n",
    "    assert sorted(tagger.objs('tag_a')) == ['obj_1', 'obj_2']  # filtered objs() method\n",
    "\n",
    "    tagger.tag_objs('tag_c', 'obj_3')\n",
    "    assert sorted(tagger.tags()) == ['tag_a', 'tag_b', 'tag_c']\n",
    "    assert sorted(tagger.tags('obj_3')) == ['tag_b', 'tag_c']  # filtered tags() method\n",
    "\n",
    "    # unfiltered objs() method\n",
    "    assert sorted(tagger.objs()) == ['obj_1', 'obj_2', 'obj_3']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72572b40",
   "metadata": {},
   "source": [
    "## Concrete Tagger (option 1): ObjTagDacc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "30b606d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import MutableMapping, Iterable, Any, NewType\n",
    "from dataclasses import dataclass\n",
    "\n",
    "Tag = NewType('Tag', str)\n",
    "Obj = NewType('Object', Any)  # or just object?\n",
    "ObjTagPairs = NewType('ObjTagPairs', MutableMapping[Obj, Tag])\n",
    "\n",
    "def flatten_set(set_of_sets):\n",
    "    return {obj for subset in set_of_sets for obj in subset}\n",
    "\n",
    "@dataclass\n",
    "class ObjTagDacc:\n",
    "    store: ObjTagPairs\n",
    "        \n",
    "    def tag_objs(self, tag: Tag, *objs: Iterable[Obj]) -> Any:\n",
    "        for obj in objs:\n",
    "            if obj in store:\n",
    "                self.store[obj].add(tag)\n",
    "            else:\n",
    "                self.store[obj] = {tag}\n",
    "\n",
    "    def tags(self, obj: Optional[Obj] = None) -> Iterable[Tag]:\n",
    "        if obj is None:\n",
    "            return flatten_set(self.store.values())\n",
    "        else:\n",
    "            return self.store[obj]\n",
    "\n",
    "    def objs(self, tag: Optional[Tag] = None) -> Iterable[Obj]:\n",
    "        # TODO: Express this filtering in such a way that will allow us to take advantage of DB specifics\n",
    "        #  (e.g., passing on the filtering to the DB instead of filtering in python itself)\n",
    "        if tag is None:\n",
    "            return self.store.keys()\n",
    "        else:\n",
    "            return (obj for obj, tags in self.store.items() if tag in tags)\n",
    "\n",
    "\n",
    "store = dict()\n",
    "tagger = ObjTagDacc(store)\n",
    "test_tagger(tagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ecd2df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de8fd45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2dd3f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeffbd9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9568fa00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
